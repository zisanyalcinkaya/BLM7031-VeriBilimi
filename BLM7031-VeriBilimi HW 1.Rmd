---
title: "R Notebook"
output: html_notebook
---


```{r}
#import libraries
library(dplyr)
library(sqldf)
library(ggplot2)
library(ggformula)
library(psych)
library(caret)
library (tree)
library (ISLR)
```


```{r}
#shows the top 6 records
head(diamonds)

#describe function gives to the basic stats information such as median,mean, min,max
describe(diamonds)

#Show attributes  
attributes(diamonds)

# Generating a summary of all data attributes with the summary() function
summary(diamonds)

# Inspecting the data source
glimpse(diamonds)

# correlation matrix
library(corrplot)
cor <- diamonds[, sapply(diamonds, is.numeric)]
cor <- cor[complete.cases(cor), ]
correlation_matrix <- cor(cor, method = "spearman")
corrplot(correlation_matrix, method="color")
```

```{r}
#Task1 Create 2 new columns using mutate, summarise, filter and other dplyr functions

df = sqldf("select min(price) min_price, max(price) max_price, avg(price) avg_price, cut,color,clarity,depth,carat from diamonds group by cut,color,clarity,depth,carat")

df


dfPC = sqldf("select count(*) miktar, sum(X+Y+Z) boyut, min(price) min_price, max(price) max_price, avg(price) avg_price,carat from diamonds group by carat")

dfPC

# When I check the class and number of missing variables, there is no missing values. Data is pretty neat. There are however, a few factor variables.
data.frame(cbind(data.frame(VarType=sapply(diamonds,class)),data.frame(Total_Missing=sapply(diamonds,function(x){sum(is.na(x))}))))

```

```{r}
#Task2 Create a ML model (decision tree, knn, regression) to predict price of diamond

#*** one hot Encoding

library(reshape2)
newdata <- dcast(data = diamonds, price ~ ., length)

# altered columns back to factors
diamonds$cut <- as.factor(diamonds$cut)
diamonds$color <- as.factor(diamonds$color)
diamonds$clarity <- as.factor(diamonds$clarity)
str(diamonds)

#Develop a prediction model using training and test sets 
set.seed(2)

#split dataset train is %80 and test is %20
train <- diamonds %>% sample_frac(.8)
test  <- anti_join(diamonds, train)

# Training The Linear Regression Model
model1 <- lm(price ~ ., data=train)
summary(model1)

# Training The Logistic Regression Model
model2 <- glm(price ~ ., data=train)
summary(model2)

#Prediction
prediction <- predict(model1, test, type = "response")

# Confusion Matrix
table(test$price, prediction >= 0.5)

#Decision Tree - Fit the Data to the model
#use the tree() function to fit a classification tree in order to predict tree() High using all variables but Sales. 
treepredmodel = tree(formula= price~., data = train )

#The summary() function lists the variables that are used as internal nodes
#in the tree, the number of terminal nodes, and the (training) error rate.
summary(treepredmodel)

# plot the trained tree 
plot(treepredmodel )
text(treepredmodel,pretty=0)





# Levels functions helps to show different levels in factor variables
print("Cut Levels")
levels(diamonds$cut)

print("Color Levels")
levels(diamonds$color)

print("Clarity Levels")
levels(diamonds$clarity)

```

